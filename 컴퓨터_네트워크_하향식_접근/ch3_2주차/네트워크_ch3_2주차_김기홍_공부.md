### 3.5절

#### R14. True or false?

##### a. 호스트 A가 TCP 연결을 통해 호스트 B에게 대용량 파일을 보내고 있습니다. 호스트 B에 호스트 A를 보낼 데이터가 없다고 가정해 보겠습니다. 호스트 B는 데이터에 대한 확인 응답을 피기백할 수 없으므로 호스트 B는 호스트 A에게 확인 응답을 보내지 않습니다.

False

이런 경우 일단 약 0.1 ~ 0.2 초 정도 버퍼에 저장해둔다. 이후 확인응답을 편승시키기 위한 송축 데이터 패킷을 찾는데, 만약 그래도 송출할 데이터 패킷을 찾지 못한다면, 확인응답은 별도의 패킷을 만들어 전송된다. 이를 "확인 응답 지연" 이라고 한다.

피기백(Piggyback) 방식이란: 네트워크 대역폭을 효율적으로 사용하기 위한 기술로 수신측에서 수신된 데이터에 대한 확인(Acknowledgement)을 즉시 보내지 않고, **전송할 데이터가 있는 경우에만** 제어 프레임을 별도로 사용하지 않고 기존의 데이터 프레임에 확인 필드를 덧붙여 전송(Piggyback)하는 흐름제어 방식을 말한다.

##### b. TCP rwnd 크기는 연결하는 동안 변하지 않는다.

False

rwnd로 명명된 수신 윈도는 버퍼의 여유공간으로 설정된다. 시간에 따라 여유 공간은 변하므로 rwnd 는 동적이다. (225페이지)

rwnd = RcvBuffer - [LastByte-Rcvd - LastByteRead]

##### c. 호스트 A는 TCP 연결로 호스트 B에 큰 파일을 보내고 있다고 가정하자. 호스트 A가 보내는 확인응답 안 된 바이트 수는 수신자 버퍼의 크기를 초과할 수 있다.

False

TCP는 흐름 제어(flow control) 메커니즘을 사용하여 송신자가 수신자의 처리 능력을 초과하지 않도록 보장하며, 이를 위해 TCP 수신 윈도우(rwnd)값을 사용한다.

전통적인 TCP의 혼잡 제어에서 cwnd 로 표시되는 혼잡 윈도는 TCP 송신자가 네트워크로 트래픽을 전송할 수 있는 속도에 제약을 가한다. 특히 송신하는 쪽에서 확인응답이 안 된 데이터의 양은 cwnd 와 rwnd 의 최솟값을 초과하지 않을 것이다.

LastByteSent - LastByteAcked <= min{cwnd, rwnd}

혹은 다음과 같이 표기할 수 있다.

송신 윈도우(swnd) = min(cwnd, rwnd)

##### d. 호스트 A는 TCP 연결로 호스트 B에 큰 파일을 보내고 있다고 가정하자. 이 연결의 한 세그먼트의 순서 번호가 m이라고 할 때, 그 다음 세그먼트에 대한 순서 번호는 반드시 m + 1이다.

False

TCP 의 seq(순서 번호, Sequence Number)는 바이트 단위로 증가하며, 세그먼트(패킷) 단위가 아니라 데이터 바이트 단위로 계산된다.

어떤 세그먼트의 데이터 크기(페이로드)가 1000 바이트라면 그 다음 세그먼트의 순서 번호는 **m + 1000** 가 된다.

##### e. TCP 세그먼트의 헤더에는 rwnd 에 대한 필드가 있다.

True

TCP 세그먼트 헤더에는 16비트의 수신 윈도(receive window) 필드가 있으며, 이 필드는 흐름 제어에 사용된다.

##### f. TCP 연결에서 최종 SampleRTT 값이 1초라고 가정하자. 그렇다면 연결에 대한 TimeoutInterval 은 반드시 1초 이상이어야 한다.

True

TCP는 패킷 재전송을 방지하고 불필요한 타임아웃을 줄이기 위해 TimeoutInterval을 SampleRTT 보다 항상 크게 설정한다.

##### g. TCP 연결상에서 호스트 A가 호스트 B에게 순서 번호가 38인 4바이트 크기의 한 세그먼트 데이터를 보낸다고 가정하자. 그렇다면 이 세그먼트의 확인응답 번호는 반드시 42다.

True

정상적으로 데이터를 수신했다면, 위의 d 문제에서처럼 **m + 바이트** 가 되야하므로 42가 맞다. (패킷 손실이나 중복 수신에서는 예외)

#### R15. 호스트 A가 2개의 TCP 세그먼트를 TCP 연결을 통해 호스트 B에 연속하여 보낸다고 가정한다. 첫 번째 세그먼트의 순서 번호는 90이고, 두 번째 순서 번호는 110이다.

##### a. 첫 번째 세그먼트의 데이터양은 얼마인가?

110 - 90 = 20바이트

##### b. 첫 번째 세그먼트는 분실되었지만 두 번째 세그먼트는 B에 도착했다고 하자. 호스트 B가 호스트 A에게 확인응답을 했다면, 응답번호는 몇 번이겠는가?

90

TCP는 순차적으로 데이터를 수신해야 하며, 순서가 맞지 않는 데이터는 보류(버퍼링)할 수도 있지만 즉시 처리하지 않는다.

1. TCP는 연속적으로 수신된 마지막 데이터를 기준으로 ACK를 보낸다.
2. 중간의 세그먼트가 손실되면, 그 지점부터 다시 받아야 하므로 손실된 데이터의 시작 위치를 ACK 번호로 보낸다.
3. 즉, 이전 데이터가 정상적으로 도착하지 않으면 이후 데이터를 받더라도 ACK 번호를 증가시키지 않는다.

따라서 호스트 B에 순서 번호 90~109의 데이터가 도착하지 않았으므로, 호스트 B는 "나는 90번부터 데이터를 필요로 한다"는 의미로 **ACK 90**을 보낸다.

#### R16. 3.5절에서 논의한 텔넷 예제를 고려해보자. 사용자가 글자 'C' 를 치고 몇 초 뒤에 글자 'R'을 친다고 하자. 'R'자를 치고 난 후, 얼마나 많은 세그먼트가 송신되고, 그 세그먼트 마다 순서 번호에는 무엇이 들어가며, 확인 필드에는 무엇이 들어가는가?

텔넷의 예제:

Seq=42, ACK=79, data='C' (호스트 A에서 B로)
Seq=79, ACK=43, data='C' (호스트 B에서 A로)
Seq=43, ACK=80 (호스트 A에서 B로)

답은 위의 예제에서 'C'를 'R'로 바꾸고, 각각의 숫자에 1씩만 더하면 된다.

답: (3개의 세그먼트)

Seq=43, ACK=80, data='R' (호스트 A에서 B로)
Seq=79, ACK=44, data='C' (호스트 B에서 A로)
Seq=44, ACK=81 (호스트 A에서 B로)

### 3.7절

#### R17. 호스트 A와 호스트 B를 고려해보자. 이들은 R kbps 의 속도를 갖는 병목인 링크상으로 서버 C에서 엄청난 크기의 파일을 보낸다. 파일을 보내기 위해 호스트들은 (MSS나 RTT 같은) 동일한 매개변수를 갖는 TCP를 이용하고, 동시에 각자의 전송을 시작한다. 호스트 A는 전체 파일을 하나의 TCP상으로 보내지만, 호스트 B는 9개의 TCP연결을 동시에 사용하는데, 파일을 9개 부분으로 나누어 각 TCP 연결로 보낸다. 파일 전송의 시작 시에 각 호스트에 의해 성취되는 전체적인 전송률은 얼마인가? 이 상황이 공평한가?

> 문제 정리:
>
> * **R kbps** 속도의 병목 링크를 통해 서버 C가 파일을 전송
> * **호스트 A** : 단일 TCP 연결을 사용
> * **호스트 B** : **9개의 TCP 연결을 동시에 사용**
> * **모든 TCP 연결이 동일한 매개변수(MSS, RTT 등)를 가짐**

모든 TCP 연결이 동일한 매개변수(MSS, RTT등)를 가지므로 공정한 대역폭 공유(fair bandwith sharing) 정첵에 의해 호스트 A는 전체 대역폭의 1/10 을 사용하고, 호스트 B는 전체 대역폭의 9/10을 사용하므로 호스트 B가 압도적으로 더 많은 대역폭을 차지하게 되어 공평하지 않다.

#### R18. 진실인가 거짓인가? TCP 에서 혼잡 제어를 고려해보자. 타이머가 송신자에서 종료된다면, ssthresh 는 기존 값의 반으로 설정한다.

True

ssthresh 의 핵심 개념 정리:

- ssthresh 는 Slow Start와 Congestion Avoidance 의 경계를 결정하는 값이다.
- 혼잡이 발생하면, ssthresh는 cwnd(혼잡 윈도우) 의 절반으로 줄어든다.
- Slow Start 모드는 ssthresh 까지 지수 증가, 이후 선형 증가로 전환된다.

#### R19. 3.7절의 [실전원리]에서 다룬 TCP 분할 논의에 따르면, TCP 분할을 한 응답 시간은 대략 4 * RTT(fe) + RTT(be) + 프로세싱 시간이다. 이는 직접 연결이 사용될 때는 4 * RTT + 처리 시간과는 대치된다. RTT(be)가 0.5 * RTT라고 하자. RTT(fe)가 어떤 값일 때 TCP 분할이 직접 연결보다 더 짧은 지연을 갖는가?

TCP 분할이 직접 연결보다 짧은 지연을 갖기 위해서는 **RTT(fe) < 0.875 × RTT(직접 연결)** 이어야 합니다.

1. **지연 시간 비교** :

* **TCP 분할**의 응답 시간:
  4×RTT(fe)+RTT(be)+프로세싱 시간**4**×**RTT(fe)**+**RTT(be)**+**프로세싱** **시간**
* **직접 연결**의 응답 시간:
  4×RTT(직접 연결)+프로세싱 시간**4**×**RTT(**직접** **연결**)**+**프로세싱** **시간**

1. **주어진 조건** :

* RTT(be)=0.5×RTT(직접 연결)**RTT(be)**=**0.5**×**RTT(**직접** **연결**)**
* 프로세싱 시간은 양쪽에서 동일하므로 비교 시 무시 가능.

1. **부등식 설정** :
   TCP 분할의 지연이 직접 연결보다 작아야 하므로:
   4×RTT(fe)+0.5×RTT(직접 연결)<4×RTT(직접 연결)**4**×**RTT(fe)**+**0.5**×**RTT(**직접** **연결**)**<**4**×**RTT(**직접** **연결**)**
2. **RTT(fe)에 대해 정리** :
   4×RTT(fe)<3.5×RTT(직접 연결)**4**×**RTT(fe)**<**3.5**×**RTT(**직접** **연결**)**RTT(fe)<3.54×RTT(직접 연결)=0.875×RTT(직접 연결)**RTT(fe)**<**4**3.5****×**RTT(**직접** **연결**)**=**0.875**×**RTT(**직접** **연결**)**

RTT(fe)가 직접 연결의 RTT보다 **87.5% 미만**일 때, TCP 분할이 더 낮은 지연을 가집니다.
